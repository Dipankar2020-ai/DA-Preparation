{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad5def68",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Kickoffs - IMDB Movie Review Analysis üçø\n",
    "\n",
    "*Given a dataset consisting of reviews posted on IMDB for movies and series. Though the dataset may seem as a CSV file, it's record comes with a little toss of HTML code with it. We need to analyze this data using NLP techniques and get some useful insights out of it.*\n",
    "\n",
    "##### After completing this challenge, you will be able to:\n",
    "+ Understand the concepts of Data preprocessing.\n",
    "+ NLP Concepts.\n",
    "+ Machine learning models using SKlearn and NLTK.\n",
    "+ Intense data pre-processing methods\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e17d94a-1dd9-4d96-897c-8dc24575517f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0050c852",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Task 1 : Data Loading and Exploration\n",
    "+ Load the IMDB reviews dataset `imdb.csv` to a pandas dataframe named `data`.\n",
    "- Utilize Pandas functions (`info()`, `head()`, `describe()`) to explore the structure, columns, and initial samples of the `data` dataset.\n",
    "- Analyze the distribution and characteristics of text features in the dataset.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd3c33b-1686-41b0-9d7f-2452e0b1b60a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('imdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a54ec86-82fb-42a7-904d-96c1380203f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     2000 non-null   object\n",
      " 1   sentiment  2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n",
      "None\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "                                                   review sentiment\n",
      "count                                                2000      2000\n",
      "unique                                               2000         2\n",
      "top     One of the other reviewers has mentioned that ...  positive\n",
      "freq                                                    1      1005\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "print(data.info())\n",
    "print(data.head())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d47f59-3cc3-49b2-97de-33880fe92f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2000.00000\n",
      "mean     1282.17500\n",
      "std       945.45511\n",
      "min        98.00000\n",
      "25%       697.75000\n",
      "50%       952.50000\n",
      "75%      1573.25000\n",
      "max      8180.00000\n",
      "Name: review, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "text_distribution = data['review'].apply(len)\n",
    "print(text_distribution.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18204d3",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Task 2 : Data Preprocessing\n",
    "+ Complete the following function `clean_text` to remove HTML tags, punctuations and stopwords for the `review` column.\n",
    "+ Using regex - remove the HTML tags, remove all the punctuations in each record.\n",
    "+ Tokenize the text data and remove all the stopwords in it. Join the tokens back into a sentence once the removal process is complete and return the cleaned text.\n",
    "+ Apply the `clean_text` function on the `reviews` column of `data` dataset and store it in a new column called `clean_review`.\n",
    "\n",
    "***Sample dataset after cleaning***:\n",
    "\n",
    "review | sentiment | clean_review\n",
    "------ | ---------- | -----------\n",
    "A wonderful little production. \\<br />\\<br />The filming technique is very unassuming- | positive | wonderful little production filming technique unassuming\n",
    "Probably my all-time favorite movie | positive | Probably alltime favorite movie\n",
    "\n",
    "**Note:** Do not modify the function name.\n",
    "<br>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f9ab17-a1a6-4efe-b47d-4c0c091bbec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Do not modify function name\n",
    "def clean_text(text):\n",
    "    ## Write your function code here\n",
    "    ## Start of coding block ##\n",
    "    clean_text = re.sub(r'<.*?>', '', text)\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', clean_text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(clean_text)\n",
    "    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "    clean_text = ' '.join(filtered_text)\n",
    "\n",
    "    ## End of coding block ##\n",
    "    return clean_text\n",
    " \n",
    "# Apply cleaning function to the 'review' column\n",
    "data['clean_review'] = data['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3082ddd",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Task 3 : Sentiment Analysis Model Building\n",
    "+ Prepare the data and labels; store them in `X` & `y` respectively.\n",
    "+ Create an instance of TF-IDF Vectorization with max features set to 5000 in variable `tfidf_vectorizer`.\n",
    "+ Fit and transform the data extracted and store it in `X_tfidf`.\n",
    "+ Split the dataset into training and testing named X_train, X_test, y_train, y_test with the newly transformed data and the labels with a test size of 20% and random state set to 42.\n",
    "+ Initialize SVM classifier with seed value of `42` stored in variable `svm`.\n",
    "+ Fit the training data to the classifier and gather the predictions against the testing data and store it in `y_pred`. \n",
    "+ Evaluate the score for predictions against the testing data and store the output in `accuracy`.\n",
    "+ Get the classification report and of the predictions and the testing data as a dictionary and store it in `report`.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f94d5d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare data and labels\n",
    "X = data['clean_review']\n",
    "y = data['sentiment']\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    " \n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ecc47a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.835\n"
     ]
    }
   ],
   "source": [
    "# Initialize SVM classifier\n",
    "svm = LinearSVC(random_state=42)\n",
    " \n",
    "# Train the classifier\n",
    "svm.fit(X_train, y_train)\n",
    " \n",
    "# Predictions\n",
    "y_pred = svm.predict(X_test)\n",
    " \n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    " \n",
    "# Classification report\n",
    "report = classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc2bccf",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Task 4 : Word Frequency Analysis\n",
    "+ Get the most common Top 10 words from the cleaned review data and store it as a dictionary.\n",
    "+ Name the dictionary as `wc_dict`. Example: {word1: count1, word2: count2}\n",
    "+ Use tokenization and counting methods to calculate word frequencies.\n",
    "\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e12dcae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analyze word frequency in the IMDb dataset\n",
    "# Display the top 10 most common words\n",
    "word_count = Counter(' '.join(data['clean_review']).split())\n",
    "wc_dict = dict(word_count.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd0fc8",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Task 5 : Average Word Length Calculation\n",
    "- Compute the average word length in characters across the text dataset and store the result in `avg_word_length`.\n",
    "- Tokenize the text and calculate the average length of tokens.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74435c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate average word length\n",
    "tokens = word_tokenize(' '.join(data['clean_review']))\n",
    "avg_word_length = sum(len(token) for token in tokens) / len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e39c80b",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> ! Note : After you finish solving the problem, please run the below cell to save your answers for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6b10dde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1 Passed\n",
      "Test Case 2 Passed\n",
      "Test Case 3 Passed\n",
      "Test Case 4 Passed\n",
      "Test Case 5 Passed\n"
     ]
    }
   ],
   "source": [
    "### Do not modify this block\n",
    "from test_imdb import test_imdb\n",
    "try:\n",
    "    test_imdb.save_answer(data, clean_text,X, y, tfidf_vectorizer,X_train, X_test, y_train, y_test,svm, y_pred, accuracy, report, wc_dict, avg_word_length)\n",
    "except:\n",
    "    print(\"Assign the answers to all the variables properly\")\n",
    "    test_imdb.remove_pickle()\n",
    "    try:\n",
    "        test_imdb.save_ans1(data, clean_text, X, y)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        test_imdb.save_ans2(tfidf_vectorizer, X_train, X_test, y_train, y_test)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        test_imdb.save_ans3(svm, y_pred)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        test_imdb.save_ans4(accuracy, report)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        test_imdb.save_ans5(wc_dict, avg_word_length)\n",
    "    except:\n",
    "        pass\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56858d1-1add-4de5-ab33-569a169636e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
